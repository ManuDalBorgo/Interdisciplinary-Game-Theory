{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 1 - Interdisciplinarity of the Prisoner's Dilemma\n",
                "\n",
                "This notebook serves as a \"grab-bag\" of Prisoner's Dilemma (PD) examples for an interdisciplinary first lecture. It combines classic intellectual lineage, matrix examples across disciplines (from lecture slides), and modern applications in AI/ML."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (A) Classic/Intellectual Lineage\n",
                "\n",
                "### Core References and Teachable \"Anchor\" Citations\n",
                "\n",
                "1.  **Origin + Naming (RAND \u2192 Tucker story)**\n",
                "    *   Historical overview and references to Flood/Dresher and Tucker\u2019s framing are summarized well in the Stanford Encyclopedia of Philosophy entry.\n",
                "    *   [Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/prisoner-dilemma/)\n",
                "\n",
                "2.  **Why PD Matters (Iteration & Emergence of Cooperation)**\n",
                "    *   Axelrod\u2019s tournament story and *The Evolution of Cooperation* remains the cleanest narrative bridge from one-shot defection to repeated-game cooperation norms.\n",
                "    *   [PhilPapers](https://philpapers.org/)\n",
                "\n",
                "3.  **Modern Theoretical Shockwave in IPD**\n",
                "    *   Zero-determinant / extortion strategies (Press & Dyson, PNAS 2012) are a great \u201cstudents didn\u2019t see that coming\u201d moment.\n",
                "    *   [PNAS: Iterated Prisoner's Dilemma contains strategies that dominate any evolutionary opponent](https://www.pnas.org/doi/10.1073/pnas.1206569109)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Matrix Examples: The Canonical PD and Interdisciplinary Variants\n",
                "\n",
                "A matrix fully describes a two-player game by displaying the payoffs to each player for every possible outcome. The general form of the Prisoner's Dilemma is defined by the inequality: $T > R > P > S$ (Temptation > Reward > Punishment > Sucker's Payoff).\n",
                "\n",
                "### 1. The Canonical Story (Criminology/Law)\n",
                "Two thieves are caught red-handed. Police interrogate them separately.\n",
                "*   If both stay silent (Cooperate), they get 1 year ($R$).\n",
                "*   If both confess (Defect), they get 2 years ($P$).\n",
                "*   If one confesses and the other is silent, the confessor goes free ($T$, 0 years) and the silent one gets 3 years ($S$).\n",
                "\n",
                "| | Silent (Col) | Confess (Col) |\n",
                "|---|---|---|\n",
                "| **Silent (Row)** | 1, 1 ($R$) | 3, 0 ($S$, $T$) |\n",
                "| **Confess (Row)**| 0, 3 ($T$, $S$) | 2, 2 ($P$) |\n",
                "*(Note: Lower numbers are better here, representing years in prison)*\n",
                "\n",
                "**Dominant Strategy**: Confess. Regardless of what the other does, confessing yields a better result (0 < 1, 2 < 3)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Economics: Mobile Device Market Share\n",
                "\n",
                "**Players**: Apple/Google vs. RIM (BlackBerry)/Microsoft\n",
                "**Actions**: {Develop New OS, Stick to Current Platform}\n",
                "\n",
                "Companies can either innovate (expensive) or stick to their current platform. If both innovate, they maintain share but at a cost. If one innovates and the other doesn't, the innovator wins big.\n",
                "\n",
                "| | New OS (Player 2) | Current Platform (Player 2) |\n",
                "|---|---|---|\n",
                "| **New OS (Player 1)** | Competitive Share ($R$) | Win, Lose ($T$, $S$) |\n",
                "| **Current (Player 1)**| Lose, Win ($S$, $T$) | Competitive Share + Decreasing Satisfaction ($P$) |\n",
                "\n",
                "*Context*: 1st Motorola mobile 1973 -> RIM dominates mid-2000s -> Google purchases Android 2005 -> Apple iPhone 2007."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Psychology: The Addict (Intertemporal Decision Problem)\n",
                "\n",
                "**Players**: Before-self (Player 1) vs. After-self (Player 2)\n",
                "**Actions**: {Clean, Relapse}\n",
                "\n",
                "Analysis of self-control as a game between a present and future self.\n",
                "\n",
                "*   **T (Temptation)**: Enjoying the drug.\n",
                "*   **S (Sucker)**: Effort to get clean (suffering).\n",
                "*   **R (Reward)**: Happy to be clean.\n",
                "*   **P (Punishment)**: Remain an addict.\n",
                "\n",
                "| | Clean (After-self) | Relapse (After-self) |\n",
                "|---|---|---|\n",
                "| **Clean (Before-self)** | $R, R$ (Happy/Clean) | $S, T$ (Effort/Enjoyment) |\n",
                "| **Relapse (Before-self)**| $T, S$ (Enjoyment/Effort) | $P, P$ (Remain Addict) |\n",
                "\n",
                "If the before-self chooses to relapse because of temptation ($T$), he is \"cheating\" on his after-self, who will have to suffer to get clean again ($S$)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. International Relations: The Security Dilemma\n",
                "\n",
                "**Players**: USA vs. Soviet Union (Cold War)\n",
                "**Actions**: {Disarm/Safe, Arm/Risk}\n",
                "\n",
                "Countries build weapons or sign agreements.\n",
                "\n",
                "*   **T (Win)**: Acquire territory, alliances, hegemony.\n",
                "*   **R (Safe)**: Peace, less spending on weapons, more on public welfare.\n",
                "*   **P (Risk)**: Spending on arms, intelligence, constant risk of war.\n",
                "*   **S (Lose)**: Surrender territory, alliances, hegemony.\n",
                "\n",
                "| | Disarm (USSR) | Arm (USSR) |\n",
                "|---|---|---|\n",
                "| **Disarm (USA)** | Safe, Safe ($R$) | Lose, Win ($S, T$) |\n",
                "| **Arm (USA)** | Win, Lose ($T, S$) | Risk of War, Risk of War ($P$) |\n",
                "\n",
                "Rule: $Win > Safe > Risk > Lose$. Result: Arms Race."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Biology: *Bacillus subtilis* Survival\n",
                "\n",
                "**Players**: Two Microbes under harsh conditions\n",
                "**Actions**: {Sporulate, Competent}\n",
                "\n",
                "Strategies involve dumping DNA (Sporulate) or taking DNA (Competent).\n",
                "\n",
                "*   **T (Strong)**: Use other's DNA to strengthen self.\n",
                "*   **R (Survive)**: Both sporulate, enough DNA to survive.\n",
                "*   **P (Risk Dying)**: Both competent, not enough DNA.\n",
                "*   **S (Weak)**: Dump DNA, become weak.\n",
                "\n",
                "| | Sporulate (M2) | Competent (M2) |\n",
                "|---|---|---|\n",
                "| **Sporulate (M1)** | Survive, Survive ($R$) | Become Weak, Continue Strong ($S, T$) |\n",
                "| **Competent (M1)** | Continue Strong, Become Weak ($T, S$) | Risk Dying, Risk Dying ($P$) |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6. Electrical Engineering: TCP Backoff Game\n",
                "\n",
                "**Players**: Two Computers\n",
                "**Actions**: {TCP Backoff, Defective}\n",
                "**Payoffs**: Delay time in ms (Lower is better)\n",
                "\n",
                "*   $T = 0ms$\n",
                "*   $R = 1ms$\n",
                "*   $P = 3ms$\n",
                "*   $S = 4ms$\n",
                "\n",
                "| | TCP Backoff (Comp 2) | Defective (Comp 2) |\n",
                "|---|---|---|\n",
                "| **TCP Backoff (Comp 1)** | 1, 1 ($R$) | 4, 0 ($S, T$) |\n",
                "| **Defective (Comp 1)** | 0, 4 ($T, S$) | 3, 3 ($P$) |\n",
                "\n",
                "Computers attempt to reduce delay time. If both back off, delay is minimal. If one defects (doesn't back off), they get 0ms delay at the expense of the other."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (B) Interdisciplinary \"Real-World\" Domains\n",
                "\n",
                "These are broad categories that the specific examples above fit into. You can map each to the PD payoff logic (temptation vs mutual benefit).\n",
                "\n",
                "**1. International Relations / Security Dilemma**  \n",
                "Arms races, crisis bargaining, alliance tensions: PD is a standard formalization in IR/security-dilemma discussions. Axelrod\u2019s framing explicitly uses trade barriers/arms-race style logic.\n",
                "*   [Stanford EE Reference](https://ee.stanford.edu/)\n",
                "\n",
                "**2. Competition / Cartels / Price Wars (Industrial Organization)**  \n",
                "Two firms prefer high prices jointly, but each has an incentive to undercut (defect). Press & Dyson explicitly list cartel behavior as a canonical PD-style application area.\n",
                "*   [PNAS](https://www.pnas.org/)\n",
                "\n",
                "**3. Public Policy: Climate Agreements**  \n",
                "Countries benefit from mutual emissions cuts; each is tempted to free-ride. This is a standard classroom mapping motivated via \u201ccollective action\u201d logic.\n",
                "*   [Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/prisoner-dilemma/)\n",
                "\n",
                "**4. Biology: Reciprocity and Evolution of Cooperation**  \n",
                "PD/IPD is central to modeling reciprocal altruism and strategy selection pressures; Axelrod\u2019s work is the standard doorway for interdisciplinary cohorts.\n",
                "*   [PhilPapers](https://philpapers.org/)\n",
                "\n",
                "**5. Behavioral Econ / Psych: Trust, Fairness, and Deviations**  \n",
                "Experiments revisiting early PD play and the role of fairness norms make a strong \u201chumans aren\u2019t Nash robots\u201d point.\n",
                "*   [SAGE Journals](https://journals.sagepub.com/)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (C) Where PD Shows Up in AI / ML\n",
                "\n",
                "**1. Multi-Agent Reinforcement Learning (MARL): PD as the \u201cFruit Fly\u201d**\n",
                "PD is used to study equilibrium selection, learning-induced non-stationarity, and reward shaping.\n",
                "*   **Sequential PD + Deep MARL**: Policies that adapt based on inferred opponent cooperativeness. ([arXiv](https://arxiv.org/))\n",
                "*   **Selective Interaction**: Agents learn *who* to interact with (IJCAI 2024).\n",
                "*   **Punishment Mechanisms (2025)**: Direct punishment changes emergence of cooperation. ([Springer](https://link.springer.com/))\n",
                "*   **Reputation-driven Cooperation (AAMAS 2025)**: Bottom-up reputation as an internal reward signal.\n",
                "\n",
                "**2. \"Learning in Games\" Theory Meets Modern RL**\n",
                "*   **Closed-form Characterization (2024)**: When Q-learning-like dynamics cooperate vs defect depends on learning rates/payoffs. ([ScienceDirect](https://www.sciencedirect.com/))\n",
                "\n",
                "**3. LLMs Playing PD and Strategic Games**\n",
                "Evaluating LLMs on consistency, susceptibility to prompts, and alignment.\n",
                "*   **NeurIPS 2024**: Experiments where LLMs exhibit different cooperation tendencies than humans and can be steered by prompting. ([NeurIPS Proceedings](https://proceedings.neurips.cc/))\n",
                "    *   *Demo Idea*: Have students propose prompts that push a model toward cooperate/defect.\n",
                "\n",
                "**4. Federated Learning (FL): Free-Riding Dilemmas**\n",
                "FL has PD-shaped incentive problems: each party wants the global model but is tempted to contribute less data/compute.\n",
                "*   **Evolutionary-game modeling of FL participation (2023)**. ([ScienceDirect](https://www.sciencedirect.com/))\n",
                "*   **Incentive-based FL overview (2025)**: Frames issues in \"dilemma/free-riding\" terms. ([arXiv](https://arxiv.org/))\n",
                "\n",
                "**5. Cooperative AI / AI Safety**\n",
                "PD as the \"minimal model\" of alignment between agents.\n",
                "*   **Foundations of Cooperative AI (AAAI 2023)**. ([AAAI](https://ojs.aaai.org/))\n",
                "*   **\"Collusion\" and emergent cooperation (2025 arXiv)**: Self-play learners converging to collusive equilibria.\n",
                "\n",
                "**6. \"AI Changes the Game\"**\n",
                "*   **Discriminatory and Samaritan AIs (2024)**: How AI behaviors shift cooperation outcomes in populations. ([Royal Society](https://royalsocietypublishing.org/))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lecture Structure Suggestion\n",
                "\n",
                "A high-yield way to structure Lecture 1 using these examples:\n",
                "\n",
                "1.  **One-shot PD**: Dominant strategy defect \u2192 Quick in-class vote.\n",
                "2.  **Iterated PD**: Why \"shadow of the future\" changes incentives (Axelrod).\n",
                "3.  **Mechanisms**: Punishment, reputation, partner choice \u2192 Jump to MARL papers that instantiate each.\n",
                "4.  **Modern AI Angles**: \n",
                "    *   LLMs in PD as behavioral subjects.\n",
                "    *   Federated Learning as a system with PD incentives.\n",
                "    *   Cooperative AI / Safety lens."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}